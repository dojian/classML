{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dojian/classML/blob/main/01_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHLcriKWLRe4"
      },
      "source": [
        "# Lab 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znCD9u8kOwCP"
      },
      "source": [
        "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
        "\n",
        "Additional points may be deducted if these requirements are not met:\n",
        "    \n",
        "* Comment your code\n",
        "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own\n",
        "* Be sure your submitted notebook includes the output of your run (Hint: go to Kernel -> Restart Kernel and Run All Cells...)\n",
        "* Try and minimize the use of the global namespace (meaning, keep things inside functions)\n",
        "* Upload your .ipynb file to Gradescope when done\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X58hOMTUH-w"
      },
      "outputs": [],
      "source": [
        "# Import the libraries we'll use below.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nNOD-Z7SzAq"
      },
      "source": [
        "## Data as matrices\n",
        "Data usually comes in the form of matrices. The Python Numpy library makes it easy to manipulate matrices efficiently. See the [Numpy Tutorial](https://docs.scipy.org/doc/numpy/user/quickstart.html) for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWlmuAMwTZ3P"
      },
      "outputs": [],
      "source": [
        "# Print these to make sure you understand what is being generated.\n",
        "A = np.array([1, 2, 3])\n",
        "B = np.arange(1, 13).reshape(3, 4)\n",
        "C = np.ones((2, 3))\n",
        "D = np.eye(3)\n",
        "print(A)\n",
        "print(B)\n",
        "print(C)\n",
        "print(D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4wvvzKoUIAN"
      },
      "source": [
        "---\n",
        "### Exercise 1: Matrix manipulation (25 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0JL5FvfOwDh"
      },
      "source": [
        "Perform the following computations using numpy functions and <span style=\"color:chocolate\">print</span> the results. Note that the `*` operator implies matrix multiplication  (typically denoted using dot notation in linear algebra) -- make sure the dimensions align!\n",
        "1. 2A + 1\n",
        "2. Sum the rows of B (Hint: pass axis=1 to the cooresponding sum function)\n",
        "3. Sum the columns of B (Hint: pass axis=0 to the cooresponding sum function)\n",
        "4. Number of elements of B greater than 5\n",
        "5. C + C\n",
        "6. A * B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJtwrjdO6TbS"
      },
      "outputs": [],
      "source": [
        "# 1. 2A+1\n",
        "print(2*A+1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2brZTHfOwDi"
      },
      "outputs": [],
      "source": [
        "# 2. Sum the rows of B (Hint: pass axis=1 to the cooresponding sum function)\n",
        "print(B.sum(axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Sum the columns of B (Hint: pass axis=0 to the cooresponding sum function)\n",
        "print(B.sum(axis=0))"
      ],
      "metadata": {
        "id": "il0ci3yUVAbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Number of elements of B greater than 5\n",
        "np.sum(B>5)"
      ],
      "metadata": {
        "id": "QcjsTHWMVBBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. C + C\n",
        "C + C"
      ],
      "metadata": {
        "id": "Xsv5pt3xVBcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. A * B\n",
        "A.reshape(1,3)@B"
      ],
      "metadata": {
        "id": "FHByB-EhVBm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJapA3NROwDi"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbCRG2-uUKCT"
      },
      "source": [
        "## Data for Supervised Learning\n",
        "Supervised learning is all about learning to make predictions: given an input $x$ (e.g. home square footage), can we produce an output $\\hat{y}$ (e.g. estimated value) as close to the actual observed output $y$ (e.g. sale price) as possible. Note that the \"hat\" above $y$ is used to denote an estimated or predicted value.\n",
        "\n",
        "Let's start by generating some artificial data. We'll create a vector of inputs, $X$, and a corresponding vector of target outputs $Y$. In general, we'll refer to invidual examples with a lowercase ($x$), and a vector or matrix containing multiple examples with a capital ($X$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ulmn_bFdU87t"
      },
      "outputs": [],
      "source": [
        "def create_1d_data(num_examples=10, w=2, b=1, random_scale=1):\n",
        "  \"\"\"Create X, Y data with a linear relationship with added noise.\n",
        "\n",
        "  Args:\n",
        "    num_examples: number of examples to generate\n",
        "    w: desired slope\n",
        "    b: desired intercept\n",
        "    random_scale: add uniform noise between -random_scale and +random_scale\n",
        "\n",
        "  Returns:\n",
        "    X and Y with shape (num_examples)\n",
        "  \"\"\"\n",
        "  X = np.arange(num_examples)\n",
        "  np.random.seed(4)  # consistent random number generation\n",
        "  deltas = np.random.uniform(low=-random_scale, high=random_scale, size=X.shape)\n",
        "  Y = b + deltas + w * X\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qJg0IiYVJ8U"
      },
      "outputs": [],
      "source": [
        "# Create some artificial data using create_1d_data.\n",
        "X, Y = create_1d_data()\n",
        "plt.scatter(X, Y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6coKbXSpXOz"
      },
      "source": [
        "---\n",
        "### Exercise 2: Models for Data (25 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PtalsOvOwDl"
      },
      "source": [
        "A model is a function that takes an input $x$ and produces a prediction $\\hat{y}$.\n",
        "\n",
        "Let's consider two possible models for this data:\n",
        "1. $M_1(x) = x+5$\n",
        "2. $M_2(x) = 2x+1$\n",
        "\n",
        "Compute the predictions of models $M_1$ and $M_2$ for the values in $X$. These predictions should be vectors of the same shape as $Y$. Then plot the prediction lines of these two models overlayed on the \"observed\" data $(X, Y)$. Use [plt.plot()](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html) to draw the lines. Note: you will generate only one plot. Make sure to include axes, titles and legend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHIY5kNXUIAP"
      },
      "outputs": [],
      "source": [
        "#compute the predictions\n",
        "M1 = X+5\n",
        "M2 = 2*X + 1\n",
        "\n",
        "#plot\n",
        "plt.scatter(X,Y, color = 'blue', label ='observed data(X,Y)')\n",
        "plt.plot(X,M1, color = 'red', label ='M1')\n",
        "plt.plot(X,M2, color = 'green', label ='M2')\n",
        "\n",
        "#add axes, titles and legend\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Y values')\n",
        "plt.title('Model 1 and Model 2 with oberserved data')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-7789KEOwDm"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH-0soZiWx9x"
      },
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "How good are our models? Intuitively, the better the model, the more closely it fits the data we have. That is, for each $x$, we'll compare $y$, the true value, with $\\hat{y}$, the predicted value. This comparison is often called the *loss* or the *error*. One common such comparison is *squared error*: $(y-\\hat{y})^2$. Averaging over all our data points, we get the *mean squared error*:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textit{MSE} = \\frac{1}{n} \\sum_{y_i \\in Y}(y_i - \\hat{y}_i)^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AyY2DpxYLI0"
      },
      "source": [
        "---\n",
        "### Exercise 3: Computing MSE (25 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXDQPZmZOwDq"
      },
      "source": [
        "Write a function for computing the MSE metric and use it to compute the MSE for the two models above, $M_1$ and $M_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCeAfI5mW9sg"
      },
      "outputs": [],
      "source": [
        "def MSE(true_values, predicted_values):\n",
        "  \"\"\"Return the MSE between true_values and predicted values.\"\"\"\n",
        "  se=(true_values - predicted_values)**2\n",
        "  total_se= np.sum(se)\n",
        "  num_se = se.size\n",
        "  return total_se/num_se\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF-x9DI2ZOKq"
      },
      "outputs": [],
      "source": [
        "print ('MSE for M1:', MSE(Y, M1))\n",
        "print ('MSE for M2:', MSE(Y, M2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0weBUnNOwDq"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDiy3OZwZlwj"
      },
      "source": [
        "## Generalization\n",
        "\n",
        "Our data $(X, Y)$ represents just a sample of all possible input-output pairs we might care about. A model will be useful to the extent we can apply it to new inputs. Consider the more complex model below, which appears to produce a much smaller mean squared error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns1siZ9DZvSY"
      },
      "outputs": [],
      "source": [
        "# Fit an 8-th degree polynomial to (X, Y). See np.polyfit for details.\n",
        "polynomial_model_coefficients = np.polyfit(X, Y, deg=8)\n",
        "polynomial_model = np.poly1d(polynomial_model_coefficients)\n",
        "M3 = polynomial_model(X)\n",
        "fig = plt.scatter(X, Y)\n",
        "plt.plot(X, M3, '-k')\n",
        "print ('MSE for M3:', MSE(Y, M3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2m9YmLMZ1EV"
      },
      "source": [
        "---\n",
        "### Exercise 4: Generalization (25 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YNG8NAJOwDs"
      },
      "source": [
        "Explain whether you expect $M_3$ to be better than $M_2$ at predicting the labels for new unseen inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Zpx79_aQEC"
      },
      "source": [
        "*Writen answer:* It depends, and it is better to check using test data. M3 might be a better model if the relationship between X and Y is truely complex and non-linear. However, M3 could be over-fitting if the true relationship is linear and the 8th-degree polynominal simply capture its noise and outliers in the training data but not learn the true distribution. If the true relationship is more linear, M2 will be a better model at predicting the labels for new unseen inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9EH9D7Faf9n"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hIdZHngdrET"
      },
      "source": [
        "## Review\n",
        "\n",
        "* In **Supervised Machine Learning**, we must start with data in the form $(X,Y)$ where $X$ are the inputs and $Y$ are the output labels.\n",
        "* A **model** is a function that maps an input $x$ to an output $y$. The model's output is referred to as a **prediction**, denoted by $\\hat{y}$.\n",
        "* We **evaluate** predictions by comparing them to the true labels. This measurement is called a **loss** or **error**. For real-valued data, **mean squared error** is a common metric.\n",
        "* A model is only as good as its ability to **generalize** to new examples."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "copyright",
        "xxOhpvdW6TbX",
        "exercise-1-key-1",
        "43ZTSJEc526U",
        "exercise-5-key-1",
        "ubHispCAA_5u",
        "exercise-6-key-1",
        "5p1IvWjfEjqm",
        "exercise-9-key-1"
      ],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}